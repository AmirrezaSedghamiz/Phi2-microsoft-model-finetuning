# QLoRA Fine-Tuning of Phi-2 for Persian Language (Experimental)

This repository contains an **experimental exploration** of fine-tuning Microsoft’s Phi-2 (2.7B) language model using **QLoRA** techniques on large Persian (Farsi) text datasets.

The goal of this project was to:
- Explore the feasibility of adapting a compact LLM to Persian
- Experiment with resource-efficient training under hardware constraints
- Learn practical trade-offs in large-scale LLM fine-tuning

⚠️ **This project is research/experimental in nature.**
The results are mixed and the model is **not intended for production use**.
